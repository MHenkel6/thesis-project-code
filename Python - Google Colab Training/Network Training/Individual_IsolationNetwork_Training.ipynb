{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Individual_IsolationNetwork_Training.ipynb","provenance":[],"collapsed_sections":["uDgzmazUXChI"],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"XRdyED2zWpUW"},"source":["#  Individual Isolation Network Training Script\n","This script contains the code necessary to train the so called \"individual\" fault *isolation* network"]},{"cell_type":"markdown","metadata":{"id":"urJ8_5pdWvpp"},"source":["# Setup\n","The script requires tensorflow version 1.15.0"]},{"cell_type":"code","metadata":{"id":"EJp8h6c9dhGt","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1601893281406,"user_tz":-120,"elapsed":96555,"user":{"displayName":"Martin Henkel","photoUrl":"","userId":"16173242434936149558"}},"outputId":"ac28a344-6a53-443b-9383-480492d46c96"},"source":["!pip install tensorflow==1.15.0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n","\u001b[K     |████████████████████████████████| 412.3MB 41kB/s \n","\u001b[?25hCollecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Collecting keras-applications>=1.0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 8.1MB/s \n","\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.12.4)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.15.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.3.0)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.18.5)\n","Collecting tensorboard<1.16.0,>=1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 72.9MB/s \n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.1)\n","Collecting tensorflow-estimator==1.15.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n","\u001b[K     |████████████████████████████████| 512kB 61.2MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.10.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.8.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.35.1)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.32.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.0) (50.3.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.2.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (2.0.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.2.0)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=79b60813dcdbc60d2e875a435a0206e480928e6152c06f28a23fb9aacb237985\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built gast\n","\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","Installing collected packages: gast, keras-applications, tensorboard, tensorflow-estimator, tensorflow\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","  Found existing installation: tensorboard 2.3.0\n","    Uninstalling tensorboard-2.3.0:\n","      Successfully uninstalled tensorboard-2.3.0\n","  Found existing installation: tensorflow-estimator 2.3.0\n","    Uninstalling tensorflow-estimator-2.3.0:\n","      Successfully uninstalled tensorflow-estimator-2.3.0\n","  Found existing installation: tensorflow 2.3.0\n","    Uninstalling tensorflow-2.3.0:\n","      Successfully uninstalled tensorflow-2.3.0\n","Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"48mgNcg8u39j"},"source":["Package Import and Dependencies"]},{"cell_type":"code","metadata":{"id":"M-byfdGQkQWW","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1601893450374,"user_tz":-120,"elapsed":265503,"user":{"displayName":"Martin Henkel","photoUrl":"","userId":"16173242434936149558"}},"outputId":"115b0559-d147-4cfa-b568-d4bb26835d79"},"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import io\n","import os\n","import shutil as sh\n","import pickle\n","from pathlib import Path\n","import random\n","# Authentication for Managing Data\n","from google.colab import drive\n","drive.mount('/content/drive')\n","rootPath = '/content/drive/My Drive/Data/'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FbcwhLDq68N_","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1601893456903,"user_tz":-120,"elapsed":272018,"user":{"displayName":"Martin Henkel","photoUrl":"","userId":"16173242434936149558"}},"outputId":"cf88f69e-93fc-48a5-c3d6-6c90390b181a"},"source":["register = np.zeros(1)\n","while not np.any(register):\n","    try:\n","        with open(rootPath + 'Isolation/Training/FileRegister.csv','r') as f:\n","            register = np.genfromtxt(f,delimiter = \",\")\n","    except:\n","        pass\n","np.shape(register)\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(97, 3)"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"jWC5DJm2u-Ei"},"source":["Preprocessing Functions\n"]},{"cell_type":"code","metadata":{"id":"GqYolrfcuwZ_"},"source":["def decode_TFRecord(exampleProto):\n","# Read TFRecord file\n","    # Define features\n","    featureDescription = {\n","        'x1': tf.VarLenFeature(dtype=tf.float32),\n","        'y1': tf.VarLenFeature(dtype=tf.float32),\n","        'z1': tf.VarLenFeature(dtype=tf.float32),\n","        'vx1': tf.VarLenFeature(dtype=tf.float32),\n","        'vy1': tf.VarLenFeature(dtype=tf.float32),\n","        'vz1':tf.VarLenFeature(dtype=tf.float32),\n","        'x2': tf.VarLenFeature(dtype=tf.float32),\n","        'y2': tf.VarLenFeature(dtype=tf.float32),\n","        'z2': tf.VarLenFeature(dtype=tf.float32),\n","        'vx2': tf.VarLenFeature(dtype=tf.float32),\n","        'vy2': tf.VarLenFeature(dtype=tf.float32),\n","        'vz2':tf.VarLenFeature(dtype=tf.float32),\n","        'x3': tf.VarLenFeature(dtype=tf.float32),\n","        'y3': tf.VarLenFeature(dtype=tf.float32),\n","        'z3': tf.VarLenFeature(dtype=tf.float32),\n","        'vx3': tf.VarLenFeature(dtype=tf.float32),\n","        'vy3': tf.VarLenFeature(dtype=tf.float32),\n","        'vz3': tf.VarLenFeature(dtype=tf.float32),\n","        'x4': tf.VarLenFeature(dtype=tf.float32),\n","        'y4': tf.VarLenFeature(dtype=tf.float32),\n","        'z4': tf.VarLenFeature(dtype=tf.float32),\n","        'vx4': tf.VarLenFeature(dtype=tf.float32),\n","        'vy4': tf.VarLenFeature(dtype=tf.float32),\n","        'vz4': tf.VarLenFeature(dtype=tf.float32),\n","        'label': tf.VarLenFeature(dtype=tf.int64),\n","        'time': tf.VarLenFeature(dtype=tf.int64),\n","        'sats': tf.VarLenFeature(dtype=tf.int64)}\n","\n","    # Extract features from serialized data\n","    return  tf.io.parse_single_example(exampleProto, featureDescription)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z635MSlBEH5w"},"source":["def preprocess(dataset,seqLen = 50):\n","    #Set the Satellite viewpoint\n","    satView = tf.constant(0,dtype=tf.int64)\n","    \n","    sats = tf.sparse.to_dense(dataset['sats'])\n","    labels = tf.sparse.to_dense(dataset['label'])\n","    time = tf.sparse.to_dense(dataset['time'])\n","\n","    x1  = tf.sparse.to_dense(dataset['x1'])\n","    y1  = tf.sparse.to_dense(dataset['y1'])\n","    z1  = tf.sparse.to_dense(dataset['z1'])\n","    vx1 = tf.sparse.to_dense(dataset['vx1'])\n","    vy1 = tf.sparse.to_dense(dataset['vy1'])\n","    vz1 = tf.sparse.to_dense(dataset['vz1'])\n","\n","    x2  = tf.sparse.to_dense(dataset['x2'])\n","    y2  = tf.sparse.to_dense(dataset['y2'])\n","    z2  = tf.sparse.to_dense(dataset['z2'])\n","    vx2 = tf.sparse.to_dense(dataset['vx2'])\n","    vy2 = tf.sparse.to_dense(dataset['vy2'])\n","    vz2 = tf.sparse.to_dense(dataset['vz2'])\n","\n","    x3  = tf.sparse.to_dense(dataset['x3'])\n","    y3  = tf.sparse.to_dense(dataset['y3'])\n","    z3  = tf.sparse.to_dense(dataset['z3'])\n","    vx3 = tf.sparse.to_dense(dataset['vx3'])\n","    vy3 = tf.sparse.to_dense(dataset['vy3'])\n","    vz3 = tf.sparse.to_dense(dataset['vz3'])\n","\n","    x4  = tf.sparse.to_dense(dataset['x4'])\n","    y4  = tf.sparse.to_dense(dataset['y4'])\n","    z4  = tf.sparse.to_dense(dataset['z4'])\n","    vx4 = tf.sparse.to_dense(dataset['vx4'])\n","    vy4 = tf.sparse.to_dense(dataset['vy4'])\n","    vz4 = tf.sparse.to_dense(dataset['vz4'])\n","\n","\n","    data = tf.stack([x1,y1,z1,vx1,vy1,vz1,\n","                     x2,y2,z2,vx2,vy2,vz2,\n","                     x3,y3,z3,vx3,vy3,vz3,\n","                     x4,y4,z4,vx4,vy4,vz4])\n","    data = tf.transpose(data)\n","\n","    # take indices only the indices where \n","    # (1) the time at the beginning of a slice is less than the time at the end \n","    # of slice (ensures continuity)\n","    # (2) the satellite index matches the provided one\n","    indices = tf.where((time[:-seqLen]<time[seqLen:]) & tf.equal(sats[:-seqLen],satView))\n","    zeros = tf.zeros_like(indices)\n","    # the indices need zeros in the second column\n","    begin = tf.stack([indices,zeros],axis = 1)\n","    begin = tf.reshape(begin,tf.shape(begin)[:2])\n","    # Construct dataset\n","    dsBegin = tf.data.Dataset.from_tensor_slices(begin)\n","\n","    # Map dataset as sequence of length seq_len and labels\n","\n","    dataSlices = dsBegin.map(lambda x: tf.slice(data,x,[seqLen,24]))\n","    # select labels for data in the same way\n","    correctLabels = tf.boolean_mask(labels,(time[:-seqLen]<time[seqLen:]) & tf.equal(sats[:-seqLen],satView))\n","    # Correct labels is a vector with a single 1 (one-hot) in the position\n","    # of the faulty thruster\n","    correctLabels = tf.one_hot(correctLabels,36,dtype=tf.int32)\n","    dataLabels = tf.data.Dataset.from_tensor_slices(correctLabels)\n","\n","    dsReturn = tf.data.Dataset.zip((dataSlices,dataLabels))\n","    return dsReturn"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ju8bipaXFi0T"},"source":["Model Definition Function"]},{"cell_type":"code","metadata":{"id":"xfk_KcmIIyuk"},"source":["def createIsolateModel(seq_len=32, batch_size=None, stateful=True, \n","              num_units=[32, 32]):\n","  source = tf.keras.Input(\n","  name='seed', shape=(seq_len, 24), \n","      batch_size=batch_size)\n","  \n","  lstm_1 = tf.keras.layers.LSTM(num_units[0], stateful=stateful, return_sequences=True,dropout=0.1, recurrent_dropout=0.1)(source)\n","  lstm_2 = tf.keras.layers.LSTM(num_units[1], stateful=stateful, return_sequences=False, dropout=0.1)(lstm_1)\n","  dense_1 = tf.keras.layers.Dense(100, activation='relu')(lstm_2)\n","  \n","  predict = tf.keras.layers.Dense(36, activation='softmax')(dense_1)\n","  \n","  return tf.keras.Model(inputs=[source], outputs=[predict])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cfm1QOs3nA3g"},"source":["# Training Options"]},{"cell_type":"code","metadata":{"id":"JPsHLLEUNZ7f"},"source":["stateful = False\n","debug = False\n","distribute = False\n","loadModel = False\n","dataSetSizeTest = True\n","satView = 0\n","name = \"isolateInd0HalfData\"\n","if debug:\n","    tf.enable_eager_execution()\n","if loadModel:\n","    checkpointPath = rootPath + 'Results/Isolation/'\n","    weightsName = 'isolateInd0_weights.11-0.62.hdf5'\n","    startEpoch = 12\n","else:\n","    startEpoch = 1\n","nEpoch = 32\n","\n","#resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n","#tf.config.experimental_connect_to_cluster(resolver)\n","#tf.tpu.experimental.initialize_tpu_system(resolver)\n","#config = tf.ConfigProto()\n","#config.gpu_options.allow_growth = True\n","#sess = tf.Session(config=config)\n","\n","# Parameter Definitions\n","\n","\n","TFinal = 5602\n","nSats = 6\n","# Define model parameters\n","nUnits = [256,356]\n","nTimesteps = 50\n","\n","if debug:\n","    batchSize = 4096\n","else:\n","    batchSize = 4096\n","learningRate = 0.001\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MxB7fZwUEoQc"},"source":["# Compile Model\n","if distribute:\n","    # Create distributed strategy\n","    # topology = tf.contrib.distribute.initialize_tpu_system()\n","    #device_assignment = tf.contrib.tpu.DeviceAssignment(topology, core_assignment=tf.contrib.tpu.SINGLE_CORE_ASSIGNMENT)\n","    #tpu_strategy = tf.contrib.distribute.TPUStrategy(device_assignment=device_assignment)\n","    #strategy = tf.distribute.experimental.TPUStrategy(resolver)\n","    strategy = tf.distribute.MirroredStrategy()\n","    if loadModel:\n","        isolateModel = tf.keras.models.load_model(checkpointPath+weightsName)\n","    else:\n","        with strategy.scope():\n","            isolateModel = createIsolateModel(seq_len=nTimesteps, stateful=stateful, num_units=nUnits, batch_size=batchSize)\n","            adams = tf.keras.optimizers.Adam(learning_rate=learningRate)\n","            sgd = tf.keras.optimizers.SGD(momentum=0.006)\n","            isolateModel.compile(optimizer=adams,\n","                            loss=tf.keras.losses.CategoricalCrossentropy(),\n","                            metrics=['categorical_accuracy']) # Compile with adam optimizer\n","else:\n","    if loadModel:\n","        isolateModel = tf.keras.models.load_model(checkpointPath+weightsName)\n","    else:\n","        isolateModel = createIsolateModel(seq_len=nTimesteps, stateful=stateful, num_units=nUnits, batch_size=batchSize)\n","    adams = tf.keras.optimizers.Adam(learning_rate=learningRate)\n","    isolateModel.compile(optimizer=adams,\n","                        loss=tf.keras.losses.CategoricalCrossentropy(),\n","                        metrics=['categorical_accuracy']) # Compile with adam optimizer\n","tf.keras.utils.plot_model(\n","    isolateModel, to_file=rootPath + 'indIsolateModel.png', show_shapes=True, show_layer_names=True,\n","    rankdir='LR', expand_nested=False, dpi=96)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XydMA-_fZqGI","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1597150757832,"user_tz":-120,"elapsed":1210,"user":{"displayName":"Martin Henkel","photoUrl":"","userId":"16173242434936149558"}},"outputId":"429bb7ad-9b96-4868-891e-d4d3bf5d8eed"},"source":["pathTrain = rootPath + 'Isolation/Training/'\n","listdirTrain = []\n","if debug:\n","    globTrain = pathTrain + 'TrainCorrected_[0].tfrecord'\n","    listdirTrain = tf.io.gfile.glob(globTrain)\n","else:\n","    if dataSetSizeTest:\n","        globTrain = pathTrain + 'TrainCorrected_[0-7].tfrecord'\n","        #glob2 = pathTrain + 'TrainCorrected_[1][0-5].tfrecord'\n","        #glob3 = pathTrain + 'TrainCorrected_[6][0-3].tfrecord'\n","        listdirTrain = tf.io.gfile.glob(globTrain) #+ tf.io.gfile.glob(glob2)# + tf.io.gfile.glob(glob3)\n","        folder = 'IndIsolate_QuarterData/'\n","    else:\n","        globTrain = pathTrain + 'TrainCorrected_[0-9].tfrecord'\n","        glob2 = pathTrain + 'TrainCorrected_[1-2][0-9].tfrecord'\n","        glob3 = pathTrain + 'TrainCorrected_[3][0-1].tfrecord'\n","        listdirTrain = tf.io.gfile.glob(globTrain) + tf.io.gfile.glob(glob2) + tf.io.gfile.glob(glob3)\n","        folder = ''\n","nFilesTrain = len(listdirTrain)\n","# Validation set\n","pathTest = rootPath + 'Isolation/Testing/'\n","if debug:\n","    globTest = pathTest + 'TestCorrected_0.tfrecord'\n","else:\n","    globTest = pathTest + 'TestCorrected_[0-9].tfrecord'\n","listdirTest = tf.io.gfile.glob(globTest)\n","nFilesTest = len(listdirTest)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['/content/drive/My Drive/Data/Isolation/Training/TrainCorrected_0.tfrecord', '/content/drive/My Drive/Data/Isolation/Training/TrainCorrected_1.tfrecord', '/content/drive/My Drive/Data/Isolation/Training/TrainCorrected_2.tfrecord', '/content/drive/My Drive/Data/Isolation/Training/TrainCorrected_3.tfrecord', '/content/drive/My Drive/Data/Isolation/Training/TrainCorrected_4.tfrecord', '/content/drive/My Drive/Data/Isolation/Training/TrainCorrected_5.tfrecord', '/content/drive/My Drive/Data/Isolation/Training/TrainCorrected_6.tfrecord', '/content/drive/My Drive/Data/Isolation/Training/TrainCorrected_7.tfrecord']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CtjVDx5EKuaH","colab":{"base_uri":"https://localhost:8080/","height":176},"executionInfo":{"status":"ok","timestamp":1597150762400,"user_tz":-120,"elapsed":1626,"user":{"displayName":"Martin Henkel","photoUrl":"","userId":"16173242434936149558"}},"outputId":"295e4838-24a1-4ee7-b3cd-7f50e81091c0"},"source":["# Batch, shuffle and repeat dataset\n","fileListDatasetTrain = tf.data.TFRecordDataset(listdirTrain)\n","decodedDataset = fileListDatasetTrain.map(decode_TFRecord)\n","processedDataset = decodedDataset.flat_map(preprocess)\n","trainDataset = processedDataset\n","trainDataset = trainDataset.repeat(nEpoch).batch(batchSize,drop_remainder = True).prefetch(tf.data.experimental.AUTOTUNE)\n","\n","# Validation Dataset\n","fileListDatasetTest = tf.data.TFRecordDataset(listdirTest)\n","decodeValDataset = fileListDatasetTest.map(decode_TFRecord)\n","processedVal = decodeValDataset.flat_map(preprocess)\n","validationDataset = processedVal.batch(batchSize,drop_remainder = True).prefetch(tf.data.experimental.AUTOTUNE)\n","# Determine steps per epoch\n","trainSteps = int(nFilesTrain*100*(TFinal-nTimesteps)/batchSize)\n","testSteps = int(nFilesTest*100*(TFinal-nTimesteps)/batchSize)\n","print(\"Training Files: {}\".format(nFilesTrain))\n","print(\"Testing Files: {}\".format(nFilesTest))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n","\n","WARNING:tensorflow:From <ipython-input-6-569c1676610a>:45: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","['/content/drive/My Drive/Data/Isolation/Testing/TestCorrected_0.tfrecord', '/content/drive/My Drive/Data/Isolation/Testing/TestCorrected_1.tfrecord', '/content/drive/My Drive/Data/Isolation/Testing/TestCorrected_2.tfrecord', '/content/drive/My Drive/Data/Isolation/Testing/TestCorrected_3.tfrecord', '/content/drive/My Drive/Data/Isolation/Testing/TestCorrected_4.tfrecord']\n","Training Files: 8\n","Testing Files: 10\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uDgzmazUXChI"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"zaomvcbJ9gbK","colab":{"base_uri":"https://localhost:8080/","height":437},"executionInfo":{"status":"ok","timestamp":1597159184891,"user_tz":-120,"elapsed":8363023,"user":{"displayName":"Martin Henkel","photoUrl":"","userId":"16173242434936149558"}},"outputId":"2a30a4a0-9d60-4043-b819-8ed0a4e65a84"},"source":["# Checkpoint to save the model every two epochs\n","checkpoint = tf.keras.callbacks.ModelCheckpoint(rootPath + \"Results/Isolation/\"+folder+name+\"_weights.{epoch:02d}-{categorical_accuracy:.4f}.hdf5\", \n","                                                monitor='categorical_accuracy', verbose=0, save_best_only=False, \n","                                                save_weights_only=False, mode='auto', save_freq = 'epoch')\n","# Stopper to stop training if loss does not improve three times in a row\n","stopper = tf.keras.callbacks.EarlyStopping(patience=3,monitor='val_loss')\n","VAL = True\n","\n","history = isolateModel.fit(trainDataset, \n","                             epochs=nEpoch, steps_per_epoch = trainSteps,\n","                            callbacks=[checkpoint,stopper], \n","                            initial_epoch = startEpoch-1,\n","                            validation_data= validationDataset if VAL else None,\n","                            validation_steps = testSteps if VAL else None)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train on 1084 steps, validate on 1355 steps\n","Epoch 1/32\n","1084/1084 [==============================] - 837s 772ms/step - loss: 2.2852 - categorical_accuracy: 0.3781 - val_loss: 1.7793 - val_categorical_accuracy: 0.4931\n","Epoch 2/32\n","1084/1084 [==============================] - 838s 773ms/step - loss: 1.8408 - categorical_accuracy: 0.4884 - val_loss: 1.7854 - val_categorical_accuracy: 0.4815\n","Epoch 3/32\n","1084/1084 [==============================] - 777s 717ms/step - loss: 1.7432 - categorical_accuracy: 0.4998 - val_loss: 1.6049 - val_categorical_accuracy: 0.5402\n","Epoch 4/32\n","1084/1084 [==============================] - 742s 685ms/step - loss: 1.6146 - categorical_accuracy: 0.5332 - val_loss: 1.5686 - val_categorical_accuracy: 0.5394\n","Epoch 5/32\n","1084/1084 [==============================] - 737s 680ms/step - loss: 1.5537 - categorical_accuracy: 0.5595 - val_loss: 1.7746 - val_categorical_accuracy: 0.5223\n","Epoch 6/32\n","1084/1084 [==============================] - 740s 682ms/step - loss: 1.5579 - categorical_accuracy: 0.5511 - val_loss: 1.5678 - val_categorical_accuracy: 0.5459\n","Epoch 7/32\n","1084/1084 [==============================] - 738s 681ms/step - loss: 1.4693 - categorical_accuracy: 0.5661 - val_loss: 1.5171 - val_categorical_accuracy: 0.5428\n","Epoch 8/32\n","1084/1084 [==============================] - 738s 681ms/step - loss: 1.4932 - categorical_accuracy: 0.5655 - val_loss: 1.4072 - val_categorical_accuracy: 0.5986\n","Epoch 9/32\n","1084/1084 [==============================] - 738s 680ms/step - loss: 1.4360 - categorical_accuracy: 0.5914 - val_loss: 1.4650 - val_categorical_accuracy: 0.5895\n","Epoch 10/32\n","1084/1084 [==============================] - 738s 681ms/step - loss: 1.4401 - categorical_accuracy: 0.5815 - val_loss: 1.4893 - val_categorical_accuracy: 0.5847\n","Epoch 11/32\n","1084/1084 [==============================] - 738s 681ms/step - loss: 1.4200 - categorical_accuracy: 0.5860 - val_loss: 1.4323 - val_categorical_accuracy: 0.5824\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sVfzagHj4BKF"},"source":["# Saving to local and to google drive\n","isolateModel.save(rootPath +'Results/Isolation/' + folder + '{0}.hdf5'.format(name), overwrite=True)\n","isolateModel.save_weights(rootPath + 'Results/Isolation/' + folder + 'weights_{0}.h5'.format(name), overwrite=True)\n","\n","# Saving the training history\n","with open(rootPath + 'Results/Isolation/' + folder + 'trainHistoryDict{0}.pkl'.format(name), 'wb') as file_pi:\n","  pickle.dump(history.history, file_pi)"],"execution_count":null,"outputs":[]}]}