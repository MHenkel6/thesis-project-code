{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Individual_DetectionNetwork_Training.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Yvo36R3rXjLf"},"source":["#  Individual Detection Network Training Script\n","This script contains the code necessary to train the so called \"individual\" fault *detection* network"]},{"cell_type":"markdown","metadata":{"id":"B3BO7bCdXsDw"},"source":["# Setup\n","The script requires tensorflow version 1.15.0"]},{"cell_type":"code","metadata":{"id":"EJp8h6c9dhGt","colab":{"base_uri":"https://localhost:8080/","height":467},"executionInfo":{"status":"ok","timestamp":1601894015120,"user_tz":-120,"elapsed":2589,"user":{"displayName":"Martin Henkel","photoUrl":"","userId":"16173242434936149558"}},"outputId":"29db4e6a-d0c2-4a02-fca7-16efa519aee9"},"source":["!pip install tensorflow==1.15.0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow==1.15.0 in /usr/local/lib/python3.6/dist-packages (1.15.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.8.1)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.0.8)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.3.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.10.0)\n","Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.15.1)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.32.0)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.2)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.15.0)\n","Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.15.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.1)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.12.4)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.35.1)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.18.5)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.2)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.2.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (50.3.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (2.0.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.2.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"48mgNcg8u39j"},"source":["Package Import and Dependencies"]},{"cell_type":"code","metadata":{"id":"M-byfdGQkQWW","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1601894016307,"user_tz":-120,"elapsed":3763,"user":{"displayName":"Martin Henkel","photoUrl":"","userId":"16173242434936149558"}},"outputId":"bc22e194-b9ca-40e4-f7d7-8e4ff313bbdc"},"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import io\n","import os\n","import pickle\n","from pathlib import Path\n","import random\n","# Authentication for Managing Data\n","from google.colab import drive\n","drive.mount('/content/drive')\n","trainPercent  = 12 # percentage of training data to use\n","\n","rootPath = '/content/drive/My Drive/Data/'\n","\n","#resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n","#tf.config.experimental_connect_to_cluster(resolver)\n","#tf.tpu.experimental.initialize_tpu_system(resolver)\n","#config = tf.ConfigProto()\n","#config.gpu_options.allow_growth = True\n","#sess = tf.Session(config=config)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FbcwhLDq68N_","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1601894016309,"user_tz":-120,"elapsed":3755,"user":{"displayName":"Martin Henkel","photoUrl":"","userId":"16173242434936149558"}},"outputId":"5b50c1b6-9716-4586-ba98-742a427fddc4"},"source":["register = np.zeros(1)\n","while not np.any(register):\n","    try:\n","        with open(rootPath + 'Detection/Training/FileRegister.csv','r') as f:\n","            register = np.genfromtxt(f,delimiter = \",\")\n","    except:\n","        pass\n","np.shape(register)\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(644, 3)"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"jWC5DJm2u-Ei"},"source":["Preprocessing Functions\n"]},{"cell_type":"code","metadata":{"id":"GqYolrfcuwZ_"},"source":["def decode_TFRecord(exampleProto):\n","# Read TFRecord file\n","    # Define features\n","    featureDescription = {\n","        'x1': tf.VarLenFeature(dtype=tf.float32),\n","        'y1': tf.VarLenFeature(dtype=tf.float32),\n","        'z1': tf.VarLenFeature(dtype=tf.float32),\n","        'vx1': tf.VarLenFeature(dtype=tf.float32),\n","        'vy1': tf.VarLenFeature(dtype=tf.float32),\n","        'vz1':tf.VarLenFeature(dtype=tf.float32),\n","        'x2': tf.VarLenFeature(dtype=tf.float32),\n","        'y2': tf.VarLenFeature(dtype=tf.float32),\n","        'z2': tf.VarLenFeature(dtype=tf.float32),\n","        'vx2': tf.VarLenFeature(dtype=tf.float32),\n","        'vy2': tf.VarLenFeature(dtype=tf.float32),\n","        'vz2':tf.VarLenFeature(dtype=tf.float32),\n","        'x3': tf.VarLenFeature(dtype=tf.float32),\n","        'y3': tf.VarLenFeature(dtype=tf.float32),\n","        'z3': tf.VarLenFeature(dtype=tf.float32),\n","        'vx3': tf.VarLenFeature(dtype=tf.float32),\n","        'vy3': tf.VarLenFeature(dtype=tf.float32),\n","        'vz3': tf.VarLenFeature(dtype=tf.float32),\n","        'x4': tf.VarLenFeature(dtype=tf.float32),\n","        'y4': tf.VarLenFeature(dtype=tf.float32),\n","        'z4': tf.VarLenFeature(dtype=tf.float32),\n","        'vx4': tf.VarLenFeature(dtype=tf.float32),\n","        'vy4': tf.VarLenFeature(dtype=tf.float32),\n","        'vz4': tf.VarLenFeature(dtype=tf.float32),\n","        'label': tf.VarLenFeature(dtype=tf.int64),\n","        'time': tf.VarLenFeature(dtype=tf.int64),\n","        'sats': tf.VarLenFeature(dtype=tf.int64)}\n","\n","    # Extract features from serialized data\n","    return  tf.io.parse_single_example(exampleProto, featureDescription)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z635MSlBEH5w"},"source":["def preprocess(dataset,seqLen = 50):\n","\n","    satView = tf.constant(0,dtype=tf.int64)\n","    sats = tf.sparse.to_dense(dataset['sats'])\n","    labels = tf.sparse.to_dense(dataset['label'])\n","    time = tf.sparse.to_dense(dataset['time'])\n","\n","    x1  = tf.sparse.to_dense(dataset['x1'])\n","    y1  = tf.sparse.to_dense(dataset['y1'])\n","    z1  = tf.sparse.to_dense(dataset['z1'])\n","    vx1 = tf.sparse.to_dense(dataset['vx1'])\n","    vy1 = tf.sparse.to_dense(dataset['vy1'])\n","    vz1 = tf.sparse.to_dense(dataset['vz1'])\n","\n","    x2  = tf.sparse.to_dense(dataset['x2'])\n","    y2  = tf.sparse.to_dense(dataset['y2'])\n","    z2  = tf.sparse.to_dense(dataset['z2'])\n","    vx2 = tf.sparse.to_dense(dataset['vx2'])\n","    vy2 = tf.sparse.to_dense(dataset['vy2'])\n","    vz2 = tf.sparse.to_dense(dataset['vz2'])\n","\n","    x3  = tf.sparse.to_dense(dataset['x3'])\n","    y3  = tf.sparse.to_dense(dataset['y3'])\n","    z3  = tf.sparse.to_dense(dataset['z3'])\n","    vx3 = tf.sparse.to_dense(dataset['vx3'])\n","    vy3 = tf.sparse.to_dense(dataset['vy3'])\n","    vz3 = tf.sparse.to_dense(dataset['vz3'])\n","\n","    x4  = tf.sparse.to_dense(dataset['x4'])\n","    y4  = tf.sparse.to_dense(dataset['y4'])\n","    z4  = tf.sparse.to_dense(dataset['z4'])\n","    vx4 = tf.sparse.to_dense(dataset['vx4'])\n","    vy4 = tf.sparse.to_dense(dataset['vy4'])\n","    vz4 = tf.sparse.to_dense(dataset['vz4'])\n","\n","    data = tf.stack([x1,y1,z1,vx1,vy1,vz1,\n","                     x2,y2,z2,vx2,vy2,vz2,\n","                     x3,y3,z3,vx3,vy3,vz3,\n","                     x4,y4,z4,vx4,vy4,vz4])\n","    data = tf.transpose(data)\n","    # take indices only the indices where \n","    # (1) the time at the beginning of a slice is less than the time at the end \n","    # of slice (ensures continuity)\n","    # (2) the satellite index matches the provided one\n","    indices = tf.where((time[:-seqLen]<time[seqLen:]) & tf.equal(sats[:-seqLen],satView))\n","    zeros = tf.zeros_like(indices)\n","    # the indices need zeros in the second column\n","    begin = tf.stack([indices,zeros],axis = 1)\n","    begin = tf.reshape(begin,tf.shape(begin)[:2])\n","    # Construct dataset\n","    dsBegin = tf.data.Dataset.from_tensor_slices(begin)\n","\n","    # Map dataset as sequence of length seq_len and labels\n","    dataSlices = dsBegin.map(lambda x: tf.slice(data,x,[seqLen,24]))\n","    # select labels for data in the same way\n","    correctLabels = tf.boolean_mask(labels,(time[:-seqLen]<time[seqLen:]) & tf.equal(sats[:-seqLen],satView))\n","    correctLabels = tf.reshape((correctLabels > 0),(-1,1))\n","    dataLabels = tf.data.Dataset.from_tensor_slices(correctLabels)\n","\n","    dsReturn = tf.data.Dataset.zip((dataSlices,dataLabels))\n","    return dsReturn"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ju8bipaXFi0T"},"source":["Model Definition Function"]},{"cell_type":"code","metadata":{"id":"xfk_KcmIIyuk"},"source":["def createDetectModel(seq_len=32, batch_size=None, stateful=True, \n","              num_units=[32, 32]):\n","  source = tf.keras.Input(\n","  name='seed', shape=(seq_len, 24), \n","      batch_size=batch_size)\n","  \n","  lstm_1 = tf.keras.layers.LSTM(num_units[0], stateful=stateful, return_sequences=True)(source)\n","  lstm_2 = tf.keras.layers.LSTM(num_units[1], stateful=stateful, return_sequences=False)(lstm_1)\n","  dense_1 = tf.keras.layers.Dense(64, activation='relu')(lstm_2)\n","  \n","  predict = tf.keras.layers.Dense(1, activation='sigmoid')(lstm_2)\n","  \n","  return tf.keras.Model(inputs=[source], outputs=[predict])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cfm1QOs3nA3g"},"source":["Training Options"]},{"cell_type":"code","metadata":{"id":"JPsHLLEUNZ7f"},"source":["stateful = False\n","debug = False\n","distribute = False\n","loadModel = False\n","satView = 0\n","name = \"detectInd0C\"\n","if debug:\n","    tf.enable_eager_execution()\n","if loadModel:\n","    checkpointPath = rootPath + 'Results/Detection/'\n","    weightsName = 'detectInd0_stateful_weights.16-0.85.hdf5'\n","    startEpoch = 17\n","else:\n","    startEpoch = 1\n","nEpoch = 20\n","# Parameter Definitions\n","\n","\n","TFinal = 5602\n","nSats = 6\n","# Define model parameters\n","nUnits = [128,128]\n","nTimesteps = 50\n","if debug:\n","    batchSize = 1024\n","else:\n","    batchSize = 4096\n","learningRate = 0.005\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MxB7fZwUEoQc","colab":{"base_uri":"https://localhost:8080/","height":149},"executionInfo":{"status":"ok","timestamp":1601894016643,"user_tz":-120,"elapsed":4057,"user":{"displayName":"Martin Henkel","photoUrl":"","userId":"16173242434936149558"}},"outputId":"d996bc89-845b-463a-b7d7-a6f6aae3f1a6"},"source":["# Set up TPU\n","if distribute:\n","    # Create distributed strategy\n","    # topology = tf.contrib.distribute.initialize_tpu_system()\n","    #device_assignment = tf.contrib.tpu.DeviceAssignment(topology, core_assignment=tf.contrib.tpu.SINGLE_CORE_ASSIGNMENT)\n","    #tpu_strategy = tf.contrib.distribute.TPUStrategy(device_assignment=device_assignment)\n","    #strategy = tf.distribute.experimental.TPUStrategy(resolver)\n","    strategy = tf.distribute.MirroredStrategy()\n","    if loadModel:\n","        detectModel = tf.keras.models.load_model(checkpointPath+weightsName)\n","    else:\n","        with strategy.scope():\n","            detectModel = createDetectModel(seq_len=nTimesteps, stateful=stateful, num_units=nUnits, batch_size=batchSize)\n","            adams = tf.keras.optimizers.Adam(learning_rate=learningRate)\n","            detectModel.compile(optimizer=adams,\n","                            loss=tf.keras.losses.BinaryCrossentropy(),\n","                            metrics=['binary_accuracy']) # Compile with adam optimizer\n","else:\n","    if loadModel:\n","        detectModel = tf.keras.models.load_model(checkpointPath+weightsName)\n","    else:\n","        detectModel = createDetectModel(seq_len=nTimesteps, stateful=stateful, num_units=nUnits, batch_size=batchSize)\n","    adams = tf.keras.optimizers.Adam(learning_rate=learningRate)\n","    detectModel.compile(optimizer=adams,\n","                        loss=tf.keras.losses.BinaryCrossentropy(),\n","                        metrics=['binary_accuracy']) # Compile with adam optimizer\n","tf.keras.utils.plot_model(\n","    detectModel, to_file=rootPath + 'indDetectModel.png', show_shapes=True, show_layer_names=True,\n","    rankdir='LR', expand_nested=False, dpi=96)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XydMA-_fZqGI","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1593506934064,"user_tz":-120,"elapsed":158531,"user":{"displayName":"Martin Henkel","photoUrl":"","userId":"16173242434936149558"}},"outputId":"539f36e5-f41a-4323-d60c-acade966068c"},"source":["pathTrain = rootPath + 'Detection/Training/'\n","listdirTrain = []\n","if debug:\n","    globTrain = pathTrain + 'Train_[0].tfrecord'\n","    listdirTrain = tf.io.gfile.glob(globTrain)\n","else:\n","    # Select the worst and best 5% of faults\n","    with open(pathTrain + 'FaultRegister.csv','r') as f:\n","        faultRegister = np.genfromtxt(f,delimiter = \",\")\n","    sortedReg = faultRegister[faultRegister[:,2].argsort()]\n","    nFiles = int(trainPercent/2 /100 * faultRegister[-1,0])\n","    fileIndices = np.concatenate([sortedReg[:nFiles,0].astype(int),sortedReg[-nFiles:,0].astype(int)])\n","    for index in fileIndices:\n","        listdirTrain.append(pathTrain + 'TrainCorrected_' + str(index) + '.tfrecord')\n","# Create File List\n","print(listdirTrain)\n","\n","# Validation set\n","pathTest = rootPath + 'Detection/Testing/'\n","if debug:\n","    globTest = pathTest + 'Test_0.tfrecord'\n","else:\n","    globTest = pathTest + 'Test_[0-5].tfrecord'\n","listdirTest = tf.io.gfile.glob(globTest)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['/content/drive/My Drive/Data/Detection/Training/TrainCorrected_478.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_499.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_20.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_205.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_326.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_460.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_221.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_43.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_94.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_232.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_510.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_46.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_366.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_153.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_317.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_273.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_296.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_486.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_415.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_448.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_402.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_348.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_226.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_204.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_473.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_332.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_504.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_501.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_349.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_147.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_452.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_371.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_427.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_8.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_69.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_63.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_431.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_379.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_1.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_506.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_356.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_151.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_227.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_26.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_465.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_252.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_405.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_293.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_434.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_142.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_454.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_53.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_134.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_309.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_144.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_383.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_330.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_223.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_68.tfrecord', '/content/drive/My Drive/Data/Detection/Training/TrainCorrected_324.tfrecord']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CtjVDx5EKuaH","colab":{"base_uri":"https://localhost:8080/","height":124},"executionInfo":{"status":"ok","timestamp":1593506936222,"user_tz":-120,"elapsed":160680,"user":{"displayName":"Martin Henkel","photoUrl":"","userId":"16173242434936149558"}},"outputId":"ec50139f-3fd6-4084-9888-fa34804eb8b4"},"source":["\n","nFilesTrain = len(listdirTrain)\n","\n","# Batch, shuffle and repeat dataset\n","fileListDatasetTrain = tf.data.TFRecordDataset(listdirTrain)\n","decodedDataset = fileListDatasetTrain.map(decode_TFRecord)\n","processedDataset = decodedDataset.flat_map(preprocess)\n","trainDataset = processedDataset\n","if not stateful:\n","    trainDataset = trainDataset.shuffle(10*batchSize)\n","trainDataset = trainDataset.repeat(nEpoch).batch(batchSize,drop_remainder = True).prefetch(tf.data.experimental.AUTOTUNE)\n","\n","\n","print(listdirTest[:5])\n","nFilesTest = len(listdirTest)\n","fileListDatasetTest = tf.data.TFRecordDataset(listdirTest)\n","decodeValDataset = fileListDatasetTest.map(decode_TFRecord)\n","processedVal = decodeValDataset.flat_map(preprocess)\n","validationDataset = processedVal.batch(batchSize,drop_remainder = True).prefetch(tf.data.experimental.AUTOTUNE)\n","# Determine steps per epoch\n","trainSteps = int(nFilesTrain*100*(TFinal-nTimesteps)/batchSize)\n","testSteps = int(nFilesTest*100*(TFinal-nTimesteps)/batchSize)\n","print(\"Training Files: {}\".format(nFilesTrain))\n","print(\"Testing Files: {}\".format(nFilesTest))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n","\n","['/content/drive/My Drive/Data/Detection/Testing/Test_1.tfrecord', '/content/drive/My Drive/Data/Detection/Testing/Test_2.tfrecord', '/content/drive/My Drive/Data/Detection/Testing/Test_3.tfrecord', '/content/drive/My Drive/Data/Detection/Testing/Test_4.tfrecord', '/content/drive/My Drive/Data/Detection/Testing/Test_5.tfrecord']\n","Training Files: 60\n","Testing Files: 6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zaomvcbJ9gbK","colab":{"base_uri":"https://localhost:8080/","height":263},"executionInfo":{"status":"ok","timestamp":1593517258425,"user_tz":-120,"elapsed":10482875,"user":{"displayName":"Martin Henkel","photoUrl":"","userId":"16173242434936149558"}},"outputId":"1cf44a79-c314-4bc7-f325-114709ded5e5"},"source":["\n","\n","\n","# Checkpoint to save the model every two epochs\n","checkpoint = tf.keras.callbacks.ModelCheckpoint(rootPath + \"Results/Detection/\"+name+\"_weights.{epoch:02d}-{binary_accuracy:.2f}.hdf5\", \n","                                                monitor='binary_accuracy', verbose=0, save_best_only=False, \n","                                                save_weights_only=False, mode='auto', save_freq = 8132)\n","# Stopper to stop training if loss does not improve three times in a row\n","stopper = tf.keras.callbacks.EarlyStopping(patience=3,monitor='val_loss')\n","VAL = True\n","\n","history = detectModel.fit(trainDataset, \n","                             epochs=nEpoch, steps_per_epoch = trainSteps,\n","                            callbacks=[checkpoint,stopper], \n","                            initial_epoch = startEpoch-1,\n","                            validation_data= validationDataset if VAL else None,\n","                            validation_steps = testSteps if VAL else None)\n","#\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train on 8132 steps, validate on 813 steps\n","Epoch 1/20\n","8132/8132 [==============================] - 1778s 219ms/step - loss: 0.3552 - binary_accuracy: 0.8447 - val_loss: 0.5564 - val_binary_accuracy: 0.8436\n","Epoch 2/20\n","8132/8132 [==============================] - 1710s 210ms/step - loss: 0.3256 - binary_accuracy: 0.8574 - val_loss: 0.5325 - val_binary_accuracy: 0.8470\n","Epoch 3/20\n","8132/8132 [==============================] - 1710s 210ms/step - loss: 0.3263 - binary_accuracy: 0.8572 - val_loss: 0.5298 - val_binary_accuracy: 0.8460\n","Epoch 4/20\n","8132/8132 [==============================] - 1706s 210ms/step - loss: 0.3172 - binary_accuracy: 0.8615 - val_loss: 0.5578 - val_binary_accuracy: 0.8492\n","Epoch 5/20\n","8132/8132 [==============================] - 1709s 210ms/step - loss: 0.3127 - binary_accuracy: 0.8650 - val_loss: 0.5300 - val_binary_accuracy: 0.8518\n","Epoch 6/20\n","8132/8132 [==============================] - 1706s 210ms/step - loss: 0.3157 - binary_accuracy: 0.8630 - val_loss: 0.5345 - val_binary_accuracy: 0.8476\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FVkeuyxWJwXM"},"source":["# Saving to local and to google drive\n","detectModel.save(rootPath +'Results/Detection/{0}.hdf5'.format(name), overwrite=True)\n","detectModel.save_weights(rootPath + 'Results/Detection/weights_{0}.h5'.format(name), overwrite=True)\n","\n","# Saving the training history\n","with open(rootPath + 'Results/Detection/trainHistoryDict{0}.pkl'.format(name), 'wb') as file_pi:\n","    pickle.dump(history.history, file_pi)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sVfzagHj4BKF","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593517391252,"user_tz":-120,"elapsed":10615694,"user":{"displayName":"Martin Henkel","photoUrl":"","userId":"16173242434936149558"}},"outputId":"e43a6349-d048-4277-8dd7-1ba92b664682"},"source":["eval = detectModel.evaluate(validationDataset,steps = testSteps)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["813/813 [==============================] - 133s 163ms/step - loss: 0.5345 - binary_accuracy: 0.8476\n"],"name":"stdout"}]}]}