{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFRecord_Verification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKeMX71BPkEA"
      },
      "source": [
        "# Verification of TFRecord writer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB-Fotg_Pot1"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJp8h6c9dhGt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "008ca2e5-6359-45cf-da0b-2f349cbe1628"
      },
      "source": [
        "!pip install tensorflow==1.15.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 38kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.33.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.12.4)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 32.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.18.5)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.35.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 47.6MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.0) (50.3.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.4.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=dcf19ed1054d0f0c8e877bf63ad7808b67e43cfe18be073ffe4df862338c700d\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-applications, tensorboard, tensorflow-estimator, gast, tensorflow\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48mgNcg8u39j"
      },
      "source": [
        "Package Import and Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-byfdGQkQWW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df817984-7c3a-4951-84ee-4922e7ed7c20"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.train as tft\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import io\n",
        "import os\n",
        "import shutil as sh\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "import random\n",
        "# Authentication for Managing Data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbcwhLDq68N_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2dc8479-03d1-4e90-a533-f22c68af61c6"
      },
      "source": [
        "rootPath = '/content/drive/My Drive/'\n",
        "register = np.zeros(1)\n",
        "while not np.any(register):\n",
        "    try:\n",
        "        with open(rootPath + 'DataRaw/Detection/Training/DataNoFault4N_32.csv','r') as f:\n",
        "            register = np.genfromtxt(f,delimiter = \",\")\n",
        "    except:\n",
        "        pass\n",
        "np.shape(register)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(141649, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWC5DJm2u-Ei"
      },
      "source": [
        "Function Definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkp0xBis8IAF"
      },
      "source": [
        "def process(fileName):\n",
        "    # Load correct File\n",
        "    with tf.io.gfile.GFile(fileName,'r') as f:\n",
        "        data = np.genfromtxt(f,delimiter = \",\")\n",
        "    # Seperate Relative Position & Velocity data\n",
        "    info = data[0,:]\n",
        "    settleIndex = 300\n",
        "    faultTime = np.ceil(info[0])\n",
        "    if faultTime<1:\n",
        "        faultTime = 1e10\n",
        "    faultSat = info[1]\n",
        "    faultThruster = info[2]\n",
        "    faultType = info[3]\n",
        "\n",
        "    posvelData = data[1:,:]\n",
        "    noRows = np.size(posvelData, 0)//24 - settleIndex\n",
        "    noCols = 6\n",
        "    dataSat1 = np.zeros([noRows, 4*noCols])\n",
        "    dataSat2 = np.zeros([noRows, 4*noCols])\n",
        "    dataSat3 = np.zeros([noRows, 4*noCols])\n",
        "    dataSat4 = np.zeros([noRows, 4*noCols])\n",
        "    dataSat5 = np.zeros([noRows, 4*noCols])\n",
        "    dataSat6 = np.zeros([noRows, 4*noCols])\n",
        "    \n",
        "    faultLabel = np.zeros([noRows, 1])\n",
        "    faultLabel[np.where(np.arange(noRows)>faultTime-settleIndex)] = 1\n",
        "    settleOffset = settleIndex * 24 \n",
        "    dataSat1[:,0*noCols:1*noCols] = posvelData[settleOffset + 0::24,0:noCols]\n",
        "    dataSat1[:,1*noCols:2*noCols] = posvelData[settleOffset + 1::24,0:noCols]\n",
        "    dataSat1[:,2*noCols:3*noCols] = posvelData[settleOffset + 2::24,0:noCols]\n",
        "    dataSat1[:,3*noCols:4*noCols] = posvelData[settleOffset + 3::24,0:noCols]\n",
        "\n",
        "    dataSat2[:,0*noCols:1*noCols] = posvelData[settleOffset + 4::24,0:noCols]\n",
        "    dataSat2[:,1*noCols:2*noCols] = posvelData[settleOffset + 5::24,0:noCols]\n",
        "    dataSat2[:,2*noCols:3*noCols] = posvelData[settleOffset + 6::24,0:noCols]\n",
        "    dataSat2[:,3*noCols:4*noCols] = posvelData[settleOffset + 7::24,0:noCols]\n",
        "\n",
        "    dataSat3[:,0*noCols:1*noCols] = posvelData[settleOffset + 8::24,0:noCols]\n",
        "    dataSat3[:,1*noCols:2*noCols] = posvelData[settleOffset + 9::24,0:noCols]\n",
        "    dataSat3[:,2*noCols:3*noCols] = posvelData[settleOffset + 10::24,0:noCols]\n",
        "    dataSat3[:,3*noCols:4*noCols] = posvelData[settleOffset + 11::24,0:noCols]\n",
        "\n",
        "    dataSat4[:,0*noCols:1*noCols] = posvelData[settleOffset + 12::24,0:noCols]\n",
        "    dataSat4[:,1*noCols:2*noCols] = posvelData[settleOffset + 13::24,0:noCols]\n",
        "    dataSat4[:,2*noCols:3*noCols] = posvelData[settleOffset + 14::24,0:noCols]\n",
        "    dataSat4[:,3*noCols:4*noCols] = posvelData[settleOffset + 15::24,0:noCols]\n",
        "\n",
        "    dataSat5[:,0*noCols:1*noCols] = posvelData[settleOffset + 16::24,0:noCols]\n",
        "    dataSat5[:,1*noCols:2*noCols] = posvelData[settleOffset + 17::24,0:noCols]\n",
        "    dataSat5[:,2*noCols:3*noCols] = posvelData[settleOffset + 18::24,0:noCols]\n",
        "    dataSat5[:,3*noCols:4*noCols] = posvelData[settleOffset + 19::24,0:noCols]\n",
        "\n",
        "    dataSat6[:,0*noCols:1*noCols] = posvelData[settleOffset + 20::24,0:noCols]\n",
        "    dataSat6[:,1*noCols:2*noCols] = posvelData[settleOffset + 21::24,0:noCols]\n",
        "    dataSat6[:,2*noCols:3*noCols] = posvelData[settleOffset + 22::24,0:noCols]\n",
        "    dataSat6[:,3*noCols:4*noCols] = posvelData[settleOffset + 23::24,0:noCols]\n",
        "\n",
        "    sats = np.arange(6)\n",
        "    sats = np.repeat(sats,noRows)\n",
        "    sats = sats.reshape(-1,1)\n",
        "    time = np.arange(settleIndex,noRows+settleIndex)\n",
        "\n",
        "    time = np.tile(time,6).reshape(-1,1)\n",
        "\n",
        "    data = np.concatenate((dataSat1,dataSat2,dataSat3,dataSat4,dataSat5,dataSat6),0)\n",
        "    labels = np.concatenate((faultLabel,faultLabel,faultLabel,faultLabel,faultLabel,faultLabel),0)\n",
        "    data = np.concatenate((data,labels,time,sats),axis = 1)\n",
        "\n",
        "    return data # ds3.map(lambda a,b,c: (a,b)), ds3.map(lambda a,b,c: c)\n",
        " "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bEITT5p6ZmO"
      },
      "source": [
        "def create_tfrecord(filePath,fileName, data):\n",
        "    # Create tfrecord\n",
        "    \n",
        "    header = ['x1','y1','z1','vx1','vy1','vz1',\n",
        "                'x2','y2','z2','vx2','vy2','vz2',\n",
        "                'x3','y3','z3','vx3','vy3','vz3',\n",
        "                'x4','y4','z4','vx4','vy4','vz4',\n",
        "                'label','time','sat']\n",
        "    # Create dict\n",
        "    x1  = tft.Feature(float_list = tft.FloatList(value = data[:,0]))\n",
        "    y1  = tft.Feature(float_list = tft.FloatList(value = data[:,1]))\n",
        "    z1  = tft.Feature(float_list = tft.FloatList(value = data[:,2]))\n",
        "    vx1 = tft.Feature(float_list = tft.FloatList(value = data[:,3]))\n",
        "    vy1 = tft.Feature(float_list = tft.FloatList(value = data[:,4]))\n",
        "    vz1 = tft.Feature(float_list = tft.FloatList(value = data[:,5]))\n",
        "\n",
        "    x2  = tft.Feature(float_list = tft.FloatList(value = data[:,6]))\n",
        "    y2  = tft.Feature(float_list = tft.FloatList(value = data[:,7]))\n",
        "    z2  = tft.Feature(float_list = tft.FloatList(value = data[:,8]))\n",
        "    vx2 = tft.Feature(float_list = tft.FloatList(value = data[:,9]))\n",
        "    vy2 = tft.Feature(float_list = tft.FloatList(value = data[:,10]))\n",
        "    vz2 = tft.Feature(float_list = tft.FloatList(value = data[:,11]))\n",
        "\n",
        "    x3  = tft.Feature(float_list = tft.FloatList(value = data[:,12]))\n",
        "    y3  = tft.Feature(float_list = tft.FloatList(value = data[:,13]))\n",
        "    z3  = tft.Feature(float_list = tft.FloatList(value = data[:,14]))\n",
        "    vx3 = tft.Feature(float_list = tft.FloatList(value = data[:,15]))\n",
        "    vy3 = tft.Feature(float_list = tft.FloatList(value = data[:,16]))\n",
        "    vz3 = tft.Feature(float_list = tft.FloatList(value = data[:,17]))\n",
        "\n",
        "    x4  = tft.Feature(float_list = tft.FloatList(value = data[:,18]))\n",
        "    y4  = tft.Feature(float_list = tft.FloatList(value = data[:,19]))\n",
        "    z4  = tft.Feature(float_list = tft.FloatList(value = data[:,20]))\n",
        "    vx4 = tft.Feature(float_list = tft.FloatList(value = data[:,21]))\n",
        "    vy4 = tft.Feature(float_list = tft.FloatList(value = data[:,22]))\n",
        "    vz4 = tft.Feature(float_list = tft.FloatList(value = data[:,23]))\n",
        "\n",
        "    label = tft.Feature(int64_list = tft.Int64List(value = data[:,24].astype(int)))\n",
        "    time  = tft.Feature(int64_list = tft.Int64List(value = data[:,25].astype(int)))\n",
        "    sats  = tft.Feature(int64_list = tft.Int64List(value = data[:,26].astype(int)))\n",
        "\n",
        "\n",
        "\n",
        "    feature_dict = {'x1':x1,'y1':y1,'z1':z1,'vx1':vx1,'vy1':vy1,'vz1':vz1,\n",
        "                    'x2':x2,'y2':y2,'z2':z2,'vx2':vx2,'vy2':vy2,'vz2':vz2,\n",
        "                    'x3':x3,'y3':y3,'z3':z3,'vx3':vx3,'vy3':vy3,'vz3':vz3,\n",
        "                    'x4':x4,'y4':y4,'z4':z4,'vx4':vx4,'vy4':vy4,'vz4':vz4,\n",
        "                    'label':label,'time':time,'sats':sats}\n",
        "    features = tft.Features(feature = feature_dict)\n",
        "    DataExample = tft.Example(features = features)\n",
        "\n",
        "    with tf.python_io.TFRecordWriter(filePath+fileName) as writer:\n",
        "        writer.write(DataExample.SerializeToString())\n",
        "    return"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqYolrfcuwZ_"
      },
      "source": [
        "def decode_TFRecord(exampleProto):\n",
        "# Read TFRecord file\n",
        "    # Define features\n",
        "    featureDescription = {\n",
        "        'x1': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'y1': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'z1': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'vx1': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'vy1': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'vz1':tf.VarLenFeature(dtype=tf.float32),\n",
        "        'x2': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'y2': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'z2': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'vx2': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'vy2': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'vz2':tf.VarLenFeature(dtype=tf.float32),\n",
        "        'x3': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'y3': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'z3': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'vx3': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'vy3': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'vz3': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'x4': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'y4': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'z4': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'vx4': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'vy4': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'vz4': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'label': tf.VarLenFeature(dtype=tf.int64),\n",
        "        'time': tf.VarLenFeature(dtype=tf.int64),\n",
        "        'sats': tf.VarLenFeature(dtype=tf.int64)}\n",
        "\n",
        "    # Extract features from serialized data\n",
        "    return  tf.io.parse_single_example(exampleProto, featureDescription)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXSOzKa0PuR1"
      },
      "source": [
        "The procedure is checked by reading a csv date file, using it to write a TFRecord file. The written TFRecord file is then parsed again and compared to the original data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XydMA-_fZqGI"
      },
      "source": [
        "filePathCheck = rootPath + 'DataRaw/Detection/Training/'\n",
        "fileName = \"DataOpenFault4N_66_404.csv\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtjVDx5EKuaH"
      },
      "source": [
        "# Read Data from Test file\n",
        "data = process(filePathCheck + fileName)\n",
        "# Create TFRecord file\n",
        "filePathWrite = rootPath + \"Colab Notebooks/Verification/\"\n",
        "fileNameCheck = 'Test_0.tfrecord'\n",
        "create_tfrecord(filePathWrite, fileNameCheck,data)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vZZO92npzpb",
        "outputId": "d5abe398-7990-4c03-e7f3-10c1723858b7"
      },
      "source": [
        "# Read Created TFRecord File\n",
        "\n",
        "readSet = tf.data.TFRecordDataset(filePathWrite+ fileNameCheck)\n",
        "# Define features\n",
        "read_features = {\n",
        "    'x1': tf.VarLenFeature(dtype=tf.float32),\n",
        "    'y1': tf.VarLenFeature(dtype=tf.float32),\n",
        "    'z1': tf.VarLenFeature(dtype=tf.float32),\n",
        "    'vx1': tf.VarLenFeature(dtype=tf.float32),\n",
        "    'vy1': tf.VarLenFeature(dtype=tf.float32),\n",
        "    'vz1':tf.VarLenFeature(dtype=tf.float32),\n",
        "    'x2': tf.VarLenFeature(dtype=tf.float32),\n",
        "    'y2': tf.VarLenFeature(dtype=tf.float32),\n",
        "    'z2': tf.VarLenFeature(dtype=tf.float32),\n",
        "    'vx2': tf.VarLenFeature(dtype=tf.float32),\n",
        "    'vy2': tf.VarLenFeature(dtype=tf.float32),\n",
        "    'vz2':tf.VarLenFeature(dtype=tf.float32),\n",
        "    'x3': tf.VarLenFeature(dtype=tf.float32),\n",
        "    'y3': tf.VarLenFeature(dtype=tf.float32),\n",
        "    'z3': tf.VarLenFeature(dtype=tf.float32),\n",
        "    'vx3': tf.VarLenFeature(dtype=tf.float32),\n",
        "    'vy3': tf.VarLenFeature(dtype=tf.float32),\n",
        "    'vz3':tf.VarLenFeature(dtype=tf.float32),\n",
        "    'x4': tf.VarLenFeature(dtype=tf.float32),\n",
        "    'y4': tf.VarLenFeature(dtype=tf.float32),\n",
        "    'z4': tf.VarLenFeature(dtype=tf.float32),\n",
        "    'vx4': tf.VarLenFeature(dtype=tf.float32),\n",
        "    'vy4': tf.VarLenFeature(dtype=tf.float32),\n",
        "    'vz4':tf.VarLenFeature(dtype=tf.float32),\n",
        "    'label': tf.VarLenFeature(dtype=tf.int64),\n",
        "    'time': tf.VarLenFeature(dtype=tf.int64),\n",
        "    'sats': tf.VarLenFeature(dtype=tf.int64)}\n",
        "\n",
        "# Extract features from serialized data\n",
        "for s in readSet.take(1):\n",
        "    feature = tf.parse_single_example(s,features = read_features)\n",
        "\n",
        "# Print features\n",
        "x1read = tf.sparse.to_dense(feature['x1']).numpy()\n",
        "x1write = data[:,0]\n",
        "print(np.sum(np.abs(x1read-x1write)/len(x1read)))\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.738364150070746e-08\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}